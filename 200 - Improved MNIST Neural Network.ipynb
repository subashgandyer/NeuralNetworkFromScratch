{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install necessary libraries\n",
    "#### If the libraries are not installed, please uncomment the code cell below and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WONT WORK WITH OLDER VERSIONS OF SCIKIT-LEARN\n",
    "# from sklearn.datasets import fetch_mldata\n",
    "# mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import fetch_openml\n",
    "# mnist = fetch_openml('mnist_784')\n",
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale\n",
    "X = X / 255\n",
    "\n",
    "# one-hot encode labels\n",
    "digits = 10\n",
    "examples = y.shape[0]\n",
    "y = y.reshape(1, examples)\n",
    "Y_new = np.eye(digits)[y.astype('int32')]\n",
    "Y_new = Y_new.T.reshape(digits, examples)\n",
    "\n",
    "# split, reshape, shuffle\n",
    "m = 60000\n",
    "m_test = X.shape[0] - m\n",
    "X_train, X_test = X[:m].T, X[m:].T\n",
    "Y_train, Y_test = Y_new[:,:m], Y_new[:,m:]\n",
    "shuffle_index = np.random.permutation(m)\n",
    "X_train, Y_train = X_train[:, shuffle_index], Y_train[:, shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = None\n",
    "    return s\n",
    "\n",
    "def compute_loss(Y, Y_hat):\n",
    "\n",
    "    L_sum = None\n",
    "    m = None\n",
    "    L = None\n",
    "\n",
    "    return L\n",
    "\n",
    "def feed_forward(X, params):\n",
    "\n",
    "    cache = {}\n",
    "\n",
    "    cache[\"Z1\"] = None\n",
    "    cache[\"A1\"] = None\n",
    "    cache[\"Z2\"] = None\n",
    "    cache[\"A2\"] = None\n",
    "\n",
    "    return cache\n",
    "\n",
    "def back_propagate(X, Y, params, cache):\n",
    "\n",
    "    dZ2 = None\n",
    "    dW2 = None\n",
    "    db2 = None\n",
    "\n",
    "    dA1 = None\n",
    "    dZ1 = None\n",
    "    dW1 = None\n",
    "    db1 = None\n",
    "\n",
    "    grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(138)\n",
    "\n",
    "# hyperparameters\n",
    "n_x = X_train.shape[0]\n",
    "n_h = 64\n",
    "learning_rate = 4\n",
    "beta = .9\n",
    "batch_size = 128\n",
    "batches = -(-m // batch_size)\n",
    "\n",
    "# initialization\n",
    "params = { \"W1\": np.random.randn(n_h, n_x) * np.sqrt(1. / n_x),\n",
    "           \"b1\": np.zeros((n_h, 1)) * np.sqrt(1. / n_x),\n",
    "           \"W2\": np.random.randn(digits, n_h) * np.sqrt(1. / n_h),\n",
    "           \"b2\": np.zeros((digits, 1)) * np.sqrt(1. / n_h) }\n",
    "\n",
    "V_dW1 = np.zeros(params[\"W1\"].shape)\n",
    "V_db1 = np.zeros(params[\"b1\"].shape)\n",
    "V_dW2 = np.zeros(params[\"W2\"].shape)\n",
    "V_db2 = np.zeros(params[\"b2\"].shape)\n",
    "\n",
    "# train\n",
    "for i in range(9):\n",
    "\n",
    "    permutation = np.random.permutation(X_train.shape[1])\n",
    "    X_train_shuffled = X_train[:, permutation]\n",
    "    Y_train_shuffled = Y_train[:, permutation]\n",
    "\n",
    "    for j in range(batches):\n",
    "\n",
    "        begin = j * batch_size\n",
    "        end = min(begin + batch_size, X_train.shape[1] - 1)\n",
    "        X = X_train_shuffled[:, begin:end]\n",
    "        Y = Y_train_shuffled[:, begin:end]\n",
    "        m_batch = end - begin\n",
    "\n",
    "        cache = feed_forward(X, params)\n",
    "        grads = back_propagate(X, Y, params, cache)\n",
    "\n",
    "        V_dW1 = (beta * V_dW1 + (1. - beta) * grads[\"dW1\"])\n",
    "        V_db1 = (beta * V_db1 + (1. - beta) * grads[\"db1\"])\n",
    "        V_dW2 = (beta * V_dW2 + (1. - beta) * grads[\"dW2\"])\n",
    "        V_db2 = (beta * V_db2 + (1. - beta) * grads[\"db2\"])\n",
    "\n",
    "        params[\"W1\"] = params[\"W1\"] - learning_rate * V_dW1\n",
    "        params[\"b1\"] = params[\"b1\"] - learning_rate * V_db1\n",
    "        params[\"W2\"] = params[\"W2\"] - learning_rate * V_dW2\n",
    "        params[\"b2\"] = params[\"b2\"] - learning_rate * V_db2\n",
    "\n",
    "    cache = feed_forward(X_train, params)\n",
    "    train_cost = compute_loss(Y_train, cache[\"A2\"])\n",
    "    cache = feed_forward(X_test, params)\n",
    "    test_cost = compute_loss(Y_test, cache[\"A2\"])\n",
    "    print(\"Epoch {}: training cost = {}, test cost = {}\".format(i+1 ,train_cost, test_cost))\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1: training cost = 0.1378727715248591, test cost = 0.14155869424926984\n",
    "Epoch 2: training cost = 0.09285908280168367, test cost = 0.10614834952641347\n",
    "Epoch 3: training cost = 0.0718319788811433, test cost = 0.09233239414575697\n",
    "Epoch 4: training cost = 0.06033785646159866, test cost = 0.08895917410435022\n",
    "Epoch 5: training cost = 0.05034265336118963, test cost = 0.08599855623555619\n",
    "Epoch 6: training cost = 0.04559926071396013, test cost = 0.0849146742515606\n",
    "Epoch 7: training cost = 0.03939415203427254, test cost = 0.08847117206625395\n",
    "Epoch 8: training cost = 0.03430658916981542, test cost = 0.08438276540786237\n",
    "Epoch 9: training cost = 0.027668805314858068, test cost = 0.08228262013335501\n",
    "Done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = feed_forward(X_test, params)\n",
    "predictions = np.argmax(cache[\"A2\"], axis=0)\n",
    "labels = np.argmax(Y_test, axis=0)\n",
    "\n",
    "print(classification_report(predictions, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "micro avg       0.98      0.98      0.98     10000\n",
    "   macro avg       0.98      0.98      0.98     10000\n",
    "weighted avg       0.98      0.98      0.98     10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
